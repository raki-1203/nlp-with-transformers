{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1ddbca-3e80-4b3b-8ba1-5cd3ee65497c",
   "metadata": {},
   "source": [
    "# Chapter 6 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9475219d-d38a-4519-8424-b66cd94826f2",
   "metadata": {},
   "source": [
    "```\n",
    "언젠가 한 번쯤 문서를 요약해야 할 때가 있음\n",
    "\n",
    "요약할 문서는 연구 논문이나 재무 실적 보고서 아니면 이메일 스레드일지도 모름\n",
    "\n",
    "생각해보면 이런 작업에는 긴 단락을 이해하고, 관련 내용을 추론하고, 원래 문서의 주제를 통합해 유창한 텍스트를 생성하는 등 다양한 능력이 필요함\n",
    "\n",
    "또 기사를 정확하게 요약하는 방법과 법률 계약서를 요약하는 방법은 매우 다르기 때문에 정교한 수준의 도메인 일반화가 필요함\n",
    "\n",
    "이런 이유로 트랜스포머를 포함한 자연어 모델에게 텍스트 요약은 어려운 작업임\n",
    "\n",
    "이런 어려움에도 불구하고 텍스트 요약은 도메인 전문가의 작업 속도를 크게 높이고 기업에서 내부 지식을 집약하고, 계약을 요약하고 소셜 미디어를 위한 자동 콘텐츠를 생성하는 등의 작업에 사용됨\n",
    "\n",
    "요약은 입력과 출력이 텍스트인 고전적인 시퀀스-투-시퀀스(Seq2Seq) 작업임\n",
    "\n",
    "요약에는 인코더-디코더 트랜스포머가 잘 맞음\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0c775-8eae-43fb-a01f-ba2381f18aa2",
   "metadata": {},
   "source": [
    "## 6.1 CNN/DailyMail 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a57848-69e1-4eaa-b527-33add66c1b58",
   "metadata": {},
   "source": [
    "```\n",
    "CNN/DailyMail 데이터셋은 300,000개 뉴스 기사와 요약의 쌍으로 구성되어 있음\n",
    "\n",
    "요약은 CNN 과 DailyMail 이 기사에 첨부한 글머리 목록의 내용인데, 요약이 본문에서 추출되지 않고 추상적이라는 중요한 특징이 있음\n",
    "\n",
    "즉, 단순한 발췌가 아니라 새로운 문장으로 구성됐다는 말임\n",
    "\n",
    "여기서는 요약을 위해 익명화 처리를 하지 않은 3.0.0 버전을 사용하겠음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e13101-ff50-4931-bf41-345fef41b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40208b50-fea5-4cd3-bf31-62d56e51b10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519034e650ca4aa29484e1c009f479af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cnn_dailymail/default to /home/heerak/.cache/huggingface/datasets/ccdv___cnn_dailymail/default/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d10d01d2f4e466a83fe10cedce41d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72e382b35f540d3b284756d22a29abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d2d117db1d45f4ab0799f6f055ab1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/376M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab4dd1e74e949e9bbe8a3f996bd6932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cnn_dailymail downloaded and prepared to /home/heerak/.cache/huggingface/datasets/ccdv___cnn_dailymail/default/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ea16d5bffa47a98ad8bef4fad17cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "# \"cnn_dailymail\" 데이터셋 다운로드 에러가 발생할 경우 대신 \"ccdv/cnn_dailymail\"을 사용하세요.\n",
    "# dataset = load_dataset('cnn_dailymail', version='3.0.0')\n",
    "dataset = load_dataset('ccdv/cnn_dailymail', version='3.0.0')\n",
    "print(f'특성: {dataset[\"train\"].column_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee826c48-eefb-4d34-8945-01435b23c392",
   "metadata": {},
   "source": [
    "```\n",
    "이 데이터셋은 세 가지 특성이 있음\n",
    "\n",
    "뉴스 기사를 담은 article, 요약에 해당하는 highlights, 기사의 고유 아이디 id \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e8f06f3-e99b-4752-aff0-de47440b2fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 (500개 문자 발췌, 총 길이: 3192):\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has n\n",
      "\n",
      "요약 (길이: 180):\n",
      "Usain Bolt wins third gold of world championship .\n",
      "Anchors Jamaica to 4x100m relay victory .\n",
      "Eighth gold at the championships for Bolt .\n",
      "Jamaica double up in women's 4x100m relay .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset['train'][1]\n",
    "print(f'기사 (500개 문자 발췌, 총 길이: {len(sample[\"article\"])}):')\n",
    "print(sample['article'][:500])\n",
    "print(f'\\n요약 (길이: {len(sample[\"highlights\"])}):')\n",
    "print(sample['highlights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22866140-cd52-4244-b707-ab6717ec135c",
   "metadata": {},
   "source": [
    "```\n",
    "기사가 요약에 비해 매우 긴 경우도 있음\n",
    "\n",
    "이 경우 17배나 차이남\n",
    "\n",
    "대부분 트랜스포머 모델의 문맥 크기가 몇 단락에 해당하는 분량인 1,000개 토큰 정도로 제한되므로, 긴 기사는 트랜스포머 모델에 문제를 일으킴\n",
    "\n",
    "이를 처리하는 표준적이면서 가장 단순한 방법은 모델의 문맥 크기에 맞춰 텍스트를 자르는 것임\n",
    "\n",
    "텍스트 끝 부분에 중요한 정보가 있다면 사라지겠지만, 이는 모델 구조의 제약으로 생기는 불가피한 선택임\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69536122-b35b-4f72-b6c6-59c58a24681f",
   "metadata": {},
   "source": [
    "## 6.2 텍스트 요약 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8030b-581a-408f-8fda-698bce698f6b",
   "metadata": {},
   "source": [
    "```\n",
    "앞의 예제 기사에 대한 출력을 정성적으로 살펴보면서 요약 작업에 많이 사용되는 트랜스포머 모델 몇 가지를 알아보자.\n",
    "\n",
    "살펴볼 모델 구조는 최대 입력 크기가 각각 다르지만 동일한 입력을 사용하고 출력을 비교하기 위해 입력 텍스트를 2,000자로 제한하겠음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df166595-837f-4309-908a-dcdcc1740ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset['train'][1]['article'][:2000]\n",
    "# 딕셔너리에 각 모델이 생성한 요약을 저장합니다.\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9b4adc-5090-43fd-ade1-961bc8ed311f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men\\'s 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. \"I\\'m proud of myself and I\\'ll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica\\'s women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men\\'s team. Fraser-Pryce, like Bolt ag'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7e747-e906-429a-aa9e-d7536ce389f5",
   "metadata": {},
   "source": [
    "```\n",
    "요약에서는 관례적으로 요약 문장을 줄바꿈으로 나눔\n",
    "\n",
    "마침표마다 그 뒤에 줄바꿈 토큰을 추가해도 되지만 그러면 'U.S.' 나 'U.N.' 같은 문자열을 처리하지 못함\n",
    "\n",
    "NLTK(Natural Language Toolkit) 패키지에는 문장의 종결과 약어에 등장하는 구두점을 구별하는 더 정교한 알고리즘이 있음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49cf444b-b896-456b-83d4-d6cc570cbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eff4cf2-1d91-4b92-a7fd-a6b7369d01cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/heerak/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6d2ceb-6552-45ff-a5d9-fdcc1e16917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'The U.S. are a country. The U.N. is an organization.'\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b918422-5785-4a64-a718-377629ba3c45",
   "metadata": {},
   "source": [
    "> 다음 절에서는 여러 개의 대규모 모델을 로드합니다. 메모리가 부족하다면 큰 모델을 작은 모델(가령 'gpt, 't5-small')로 바꾸거나 이 절을 건너뛰고 6.5절 'CNN/DailyMail 데이터셋에서 PEGASUS 평가하기'로 이동하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d9b55-cc2a-484f-ac6f-08366b513c3a",
   "metadata": {},
   "source": [
    "### 6.2.1 요약 기준 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b147a4-3233-4c4e-9bb1-981f11cff981",
   "metadata": {},
   "source": [
    "```\n",
    "기사를 요약하는 일반적인 기준 모델(Baseline)은 단순히 기사에서 맨 처음 문장 세 개를 선택하는 것임\n",
    "\n",
    "이런 기준 모델은 NLTK 문장 토크나이저로 쉽게 구현할 수 있음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "404375f8-ddbf-4bd8-a5bc-cff4bab5debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return '\\n'.join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "384d6861-c323-4bdd-931f-fc625507a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['baseline'] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc9cd5a7-82ae-4e84-9413-d0612411e728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': \"(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\\nThe fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9881d81-64d0-498d-8ac7-96539fd9aeb0",
   "metadata": {},
   "source": [
    "## 6.2.2 GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a1d14-361c-48f4-8a4f-ad91951f95c2",
   "metadata": {},
   "source": [
    "```\n",
    "이 모델은 입력 텍스트 뒤에 \"TL;DR\" 을 추가해 요약을 생성하는 놀라운 기능을 발휘함\n",
    "\n",
    "너무 길어 읽지 않았다(Too Long; Didn't Read)는 문구의 약어 \"TL;DR\"은 레딧(Reddit) 같은 사이트에서 긴 포스트를 짧게 요약 할 때 종종 사용됨\n",
    "\n",
    "트랜스포머스의 pipeline() 함수로 원본 논문의 방식을 재현하며 요약 작업을 실험해보겠음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05747460-84c5-440b-96e4-1f2a21346579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 13:58:15.053410: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 13:58:15.770049: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2023-02-01 13:58:15.770147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2023-02-01 13:58:15.770154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a69dbaba-6109-4220-a426-d8e8635b4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01e41697-92d6-4f04-9955-8bf7e97feb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b99095c052e418eab4cd9cdbde67098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd615470bc2495696dae39e31bbe3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03eda06e42e041a5b421dade2f92ff7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaeaf0b7c071410e865d2a6031feafa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# 코랩의 경우 gpt2-xl 을 사용하면 메모리 부족 에러가 발생함\n",
    "# 대신 \"gpt\" 또는 \"gpt2-large\" 로 지정하거나 코랩 프로를 사용하세요.\n",
    "pipe = pipeline('text-generation', model='gpt2-xl')\n",
    "\n",
    "gpt2_query = sample_text + '\\nTL;DR:\\n'\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd414502-0750-4522-bf08-8df069e92243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men\\'s 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. \"I\\'m proud of myself and I\\'ll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica\\'s women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men\\'s team. Fraser-Pryce, like Bolt ag\\nTL;DR:\\nNesta, the fastest man in the world.\\nGatlin, the most successful Olympian ever.\\nKemar, a Jamaican legend.\\nShelly-Ann, the fastest woman ever.\\nBolt, the world\\'s greatest athlete.\\nThe team sport of pole vaulting'}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abe23a5e-0bfb-49d9-bf58-fe9fbd5bcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['gpt2'] = '\\n'.join(sent_tokenize(pipe_out[0]['generated_text'][len(gpt2_query):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2237ccd2-3bf3-4470-87f5-63871d3b7556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': \"(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\\nThe fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\",\n",
       " 'gpt2': \"Nesta, the fastest man in the world.\\nGatlin, the most successful Olympian ever.\\nKemar, a Jamaican legend.\\nShelly-Ann, the fastest woman ever.\\nBolt, the world's greatest athlete.\\nThe team sport of pole vaulting\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11003c-66b3-4138-8aa6-1f7b8aa9c2ad",
   "metadata": {},
   "source": [
    "### 6.2.3 T5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e286ed-3c9e-43f2-a75a-5fca4da169b4",
   "metadata": {
    "id": "cb3xKSwIjcUp"
   },
   "source": [
    "<img alt=\"T5\" width=\"700\" caption=\"Diagram of T5's text-to-text framework (courtesy of Colin Raffel); besides translation and summarization, the CoLA (linguistic acceptability) and STSB (semantic similarity) tasks are shown\" src=\"https://github.com/rickiepark/nlp-with-transformers/blob/main/images/chapter08_t5.png?raw=1\" id=\"T5\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f4674-3687-4784-a451-6a1f680362c3",
   "metadata": {},
   "source": [
    "```\n",
    "T5 체크포인트는 요약을 포함해 여러 작업에서 (마스킹된 단어를 재구성하기 위한) 비지도 학습 데이터와 지도 학습 데이터를 섞은 데이터로 훈련됐음\n",
    "\n",
    "따라서 미세 튜닝 없이 이 체크포인트를 사전 훈련에 썼던 것과 동일한 프롬프트를 사용해 바로 요약에 사용할 수 있음\n",
    "\n",
    "문서 요약에 사용할 모델의 입력 포맷은 \"summarize: <ARTICLE>\" 이고, 번역에 사용할 입력 포맷은 \"translate English to German: <TEXT>\" \n",
    "\n",
    "이런 입력 포맷으로 T5 는 많은 작업을 해결하는 매우 다재다능한 모델임\n",
    "\n",
    "요약을 위해 piepline() 함수로 T5 를 바로 로드하겠음\n",
    "\n",
    "이 함수는 입력을 텍스트-투-텍스트 포맷으로 처리하므로 앞에 \"summarize\" 를 붙일 필요가 없음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f530f9a7-cb0d-4de4-8d6c-7f9dcf83a26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26874a57cb34eeca8d03bae388a15aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e0dea36a034d04b5f60a674354c141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b1cae1d4ff46718da9a72aed87b802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf61db2105747c7ab373f040dd1a79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline('summarization', model='t5-large')\n",
    "pipe_out = pipe(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e593200-d275-4196-86c6-22805eea4d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"usain bolt wins his third gold medal of the world championships in the men's 4x100m relay . the 26-year-old anchored Jamaica to victory in the event in the Russian capital . he has now collected eight gold medals at the championships, equaling the record .\"}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cf8fa0f-484e-4808-b477-3969da3d5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['t5'] = '\\n'.join(sent_tokenize(pipe_out[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "867dca6d-dbf0-4ee6-8b7a-9d90c30c2327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': \"(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\\nThe fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\",\n",
       " 'gpt2': \"Nesta, the fastest man in the world.\\nGatlin, the most successful Olympian ever.\\nKemar, a Jamaican legend.\\nShelly-Ann, the fastest woman ever.\\nBolt, the world's greatest athlete.\\nThe team sport of pole vaulting\",\n",
       " 't5': \"usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\\nthe 26-year-old anchored Jamaica to victory in the event in the Russian capital .\\nhe has now collected eight gold medals at the championships, equaling the record .\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e9ce9-6609-4128-8590-f5127241e05f",
   "metadata": {},
   "source": [
    "### 6.2.4 BART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c272a-45e2-4ae9-9f32-08be64ba6f37",
   "metadata": {},
   "source": [
    "```\n",
    "BART 도 인코더-디코더 구조를 사용하는 모델로 손상된 입력을 재구성하도록 훈련됐음\n",
    "\n",
    "여기서는 특별히 CNN/DailyMail 데이터셋에 미세 튜닝된 facebook/bart-large-cnn 체크포인트를 사용하겠음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b0f654c-867b-4201-8cc6-896fcc9c6ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788b7334907b450e83a8a453252d2d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e54cef174c3428998b8302f25d224d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e809d77acf6b40f997e4b653167713a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64316523db4f469683c410bbaf0c8a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254918413f2b46e4ac7f6cffec1de19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "pipe_out = pipe(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e7fd5d7-c265-4c6d-9318-3d20137a67e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"Usain Bolt wins his third gold of the world championships in Moscow. Bolt anchors Jamaica to victory in the men's 4x100m relay. The 26-year-old has now won eight gold medals at world championships. Jamaica's women also win gold in the relay, beating France in the process.\"}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "545b01bc-1dcc-4e4d-972e-7b0f81afb160",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['bart'] = '\\n'.join(sent_tokenize(pipe_out[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8eae75f0-f707-4b18-a6a6-6dc7995a771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': \"(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\\nThe fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\",\n",
       " 'gpt2': \"Nesta, the fastest man in the world.\\nGatlin, the most successful Olympian ever.\\nKemar, a Jamaican legend.\\nShelly-Ann, the fastest woman ever.\\nBolt, the world's greatest athlete.\\nThe team sport of pole vaulting\",\n",
       " 't5': \"usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\\nthe 26-year-old anchored Jamaica to victory in the event in the Russian capital .\\nhe has now collected eight gold medals at the championships, equaling the record .\",\n",
       " 'bart': \"Usain Bolt wins his third gold of the world championships in Moscow.\\nBolt anchors Jamaica to victory in the men's 4x100m relay.\\nThe 26-year-old has now won eight gold medals at world championships.\\nJamaica's women also win gold in the relay, beating France in the process.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25201a-2c78-419f-8069-07f0a72e7bc0",
   "metadata": {},
   "source": [
    "### 6.2.5 PEGASUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2cbf8-df95-4bfc-ab05-8039f83566f3",
   "metadata": {
    "id": "HgHBlHFbjcUq"
   },
   "source": [
    "<img alt=\"pegasus\" width=\"700\" caption=\"Diagram of PEGASUS architecture (courtesy of Jingqing Zhang et al.)\" src=\"https://github.com/rickiepark/nlp-with-transformers/blob/main/images/chapter08_pegasus.png?raw=1\" id=\"pegasus\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ea7b4-02c8-4b0c-8553-975a9d8420f5",
   "metadata": {},
   "source": [
    "```\n",
    "PEGASUS 는 BART 와 마찬가지로 인코더-디코더 트랜스포머임\n",
    "\n",
    "이 모델은 여러 문장으로 구성된 텍스트에서 마스킹된 문장을 예측하는 사전 훈련 목표로 훈련됐음\n",
    "\n",
    "논문의 저자들은 사전 훈련 목표가 후속 작업에 가까울수록 더 효과적이라고 주장함\n",
    "\n",
    "일반적인 언어 모델링보다 요약에 특화된 사전 훈련 목표를 찾기 위해 대규모 말뭉치에서 (내용 중복을 측정하는 요약 평가 지표를 사용해) 주변 문단의 내용을 대부분 담은 문장을 자동으로 식별했음\n",
    "\n",
    "이런 문장을 재구성하도록 PEGASUS 모델을 사전 훈련해 최고 수준의 텍스트 요약 모델을 얻었음\n",
    "\n",
    "이 모델은 줄바꿈하는 특수 토큰이 있으므로 sent_tokenize() 함수를 사용할 필요가 없음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5703294e-4b16-4377-a0ae-3477781a57b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abb67dfdf904f1e9ef82941aaca0ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdd99ae081345aa902a56170e2303b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0932962afa48de90c552c3167eca7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6403ad08064ef584ab664a846541c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25d4a4124a341789d1375cf0d4aada1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline('summarization', model='google/pegasus-cnn_dailymail')\n",
    "pipe_out = pipe(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "419a7058-a0f7-421d-b5c6-8f1b6dc7f366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"Usain Bolt wins third gold of world championships .<n>Anchors Jamaica to victory in men's 4x100m relay .<n>Eighth gold at the championships for Bolt .<n>Jamaica also win women's 4x100m relay .\"}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "192491cf-2fa9-4a94-b670-8fc97a9a7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['pegasus'] = pipe_out[0]['summary_text'].replace(' .<n>', '.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f59af91-ed03-45d2-a65d-4ff5db4042cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': \"(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\\nThe fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\",\n",
       " 'gpt2': \"Nesta, the fastest man in the world.\\nGatlin, the most successful Olympian ever.\\nKemar, a Jamaican legend.\\nShelly-Ann, the fastest woman ever.\\nBolt, the world's greatest athlete.\\nThe team sport of pole vaulting\",\n",
       " 't5': \"usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\\nthe 26-year-old anchored Jamaica to victory in the event in the Russian capital .\\nhe has now collected eight gold medals at the championships, equaling the record .\",\n",
       " 'bart': \"Usain Bolt wins his third gold of the world championships in Moscow.\\nBolt anchors Jamaica to victory in the men's 4x100m relay.\\nThe 26-year-old has now won eight gold medals at world championships.\\nJamaica's women also win gold in the relay, beating France in the process.\",\n",
       " 'pegasus': \"Usain Bolt wins third gold of world championships.\\nAnchors Jamaica to victory in men's 4x100m relay.\\nEighth gold at the championships for Bolt.\\nJamaica also win women's 4x100m relay .\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ba194-fe21-4039-9fa0-be0bc5cad650",
   "metadata": {},
   "source": [
    "## 6.3 요약 결과 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4c248-3c47-412e-a588-15fcfaf52810",
   "metadata": {},
   "source": [
    "```\n",
    "한 모델(GPT-2)은 데이터셋에서 전혀 훈련되지 않았다는 점을 기억하자.\n",
    "\n",
    "한 모델(T5)은 여러 작업 중의 하나로 이 작업을 위해 미세 튜닝했음\n",
    "\n",
    "두 모델(BART 와 PEGASUS)은 이 작업만을 위해 미세 튜닝됐음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "692e6af5-69d6-495a-b2d0-39201e39f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Usain Bolt wins third gold of world championship .\n",
      "Anchors Jamaica to 4x100m relay victory .\n",
      "Eighth gold at the championships for Bolt .\n",
      "Jamaica double up in women's 4x100m relay .\n",
      "\n",
      "BASELINE\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\n",
      "The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\n",
      "The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\n",
      "\n",
      "GPT2\n",
      "Nesta, the fastest man in the world.\n",
      "Gatlin, the most successful Olympian ever.\n",
      "Kemar, a Jamaican legend.\n",
      "Shelly-Ann, the fastest woman ever.\n",
      "Bolt, the world's greatest athlete.\n",
      "The team sport of pole vaulting\n",
      "\n",
      "T5\n",
      "usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\n",
      "the 26-year-old anchored Jamaica to victory in the event in the Russian capital .\n",
      "he has now collected eight gold medals at the championships, equaling the record .\n",
      "\n",
      "BART\n",
      "Usain Bolt wins his third gold of the world championships in Moscow.\n",
      "Bolt anchors Jamaica to victory in the men's 4x100m relay.\n",
      "The 26-year-old has now won eight gold medals at world championships.\n",
      "Jamaica's women also win gold in the relay, beating France in the process.\n",
      "\n",
      "PEGASUS\n",
      "Usain Bolt wins third gold of world championships.\n",
      "Anchors Jamaica to victory in men's 4x100m relay.\n",
      "Eighth gold at the championships for Bolt.\n",
      "Jamaica also win women's 4x100m relay .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('GROUND TRUTH')\n",
    "print(dataset['train'][1]['highlights'])\n",
    "print()\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd01a54-4f97-42b2-be67-94223f047791",
   "metadata": {},
   "source": [
    "```\n",
    "모델 출력에서 가장 먼저 눈에 띄는 것은 GPT-2 가 생성한 요약이 다른 결과와 크게 다른 것임\n",
    "\n",
    "텍스트를 요약하는 대신 등장인물을 요약했음\n",
    "\n",
    "GPT-2 모델은 진짜 요약을 생성하도록 명시적으로 훈련되지 않았기 때문에 종종 사실을 지어내거나 환상을 만들어냄\n",
    "\n",
    "정답 요약과 다른 세 모델의 요약을 비교하면 놀랄 정도로 많이 중복되며 그 중 PEGASUS 출력과 가장 비슷함\n",
    "\n",
    "몇 개의 모델을 조사했으니, 제품 환경에 어떤 모델을 사용할지 결정하자.\n",
    "\n",
    "네 가지 모델 모두 정성적으로 합리적인 결과를 냈음\n",
    "\n",
    "몇 개의 샘플을 더 생성해봐도 되지만, 이는 최선의 모델을 결정하는 체계적인 방법이 아님\n",
    "\n",
    "지표를 하나 정의하고 특정 벤치마크 데이터셋에서 모든 모델을 평가해서 성능이 최고인 모델을 선택하는 것이 이상적인 방법임\n",
    "\n",
    "하지만 어떻게 지표를 정의해야 텍스트 생성에 좋은 모델을 판별해낼까?\n",
    "\n",
    "지금까지 본 정확도, 재현율, 정밀도 같은 표준 지표는 이 작업에 적용하기가 쉽지 않음\n",
    "\n",
    "사람이 쓴 '정답' 요약마다 동의어를 쓰거나 다른 말로 바꿔 쓰거나 사실을 조금 다르게 작성하는 식으로, 수십 개의 요약이 가능하기 때문임\n",
    "\n",
    "다음 절에서 생성된 텍스트의 품질을 측정하기 위해 개발된 일반적인 지표를 알아보자.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091be416-7ebf-42ff-a8b0-3ac59eb53583",
   "metadata": {},
   "source": [
    "## 6.4 생성된 텍스트 품질 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bfe791-744e-43a6-b9b0-c8f6e1b6e611",
   "metadata": {},
   "source": [
    "```\n",
    "평가 지표는 모델을 훈련할 때만이 아니라 나중에 제품 환경에서도 모델 성능을 평가하기 때문에 중요함\n",
    "\n",
    "평가 지표가 나쁘면 모델의 성능 저하를 눈치 채지 못하고, 평가 지표가 비즈니스 목표에 맞지 않으면 어떤 가치도 창출하지 못함\n",
    "\n",
    "텍스트 생성 작업의 성능 측정은 감성 분석이나 개체명 인식 같은 표준적인 분류 작업만큼 쉽지 않음\n",
    "\n",
    "번역을 예로 들어보자.\n",
    "\n",
    "'나는 개를 좋아한다!' 는 뜻의 'I love dogs!' 영어 문장은 스페인어로 'i Me encantan los perros!' 또는 'i Me gustan los perros!' 처럼 여러 번역이 가능함\n",
    "\n",
    "단순히 참조 번역과 정확히 일치하는지 확인하는 것이 최선의 선택은 아님\n",
    "\n",
    "우리는 조금씩 다르게 글을 쓰기 때문에 (심지어 한 사람이 쓴 글도 날마다 때마다 달라짐) 사람도 이런 지표로는 낮은 점수를 받음\n",
    "\n",
    "생성된 텍스트를 평가하는 데 가장 널리 사용되는 두 지표는 BLEU 와 ROUGE 입니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202fe4e0-3544-4647-b07a-6f0e9164b996",
   "metadata": {},
   "source": [
    "### 6.4.1 BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616740f-4835-4db8-b45b-1c63562f1337",
   "metadata": {},
   "source": [
    "```\n",
    "생성된 텍스트에서 얼마나 많은 토큰이 참조 텍스트 토큰과 완벽하게 똑같이 정렬됐는지 확인하는 대신, 단어 또는 n-그램을 체그함\n",
    "\n",
    "BLEU 는 정밀도를 근간으로 하는 지표임\n",
    "\n",
    "두 텍스트를 비교할 때 참조 텍스트에 있는 단어가 생성된 텍스트에 얼마나 자주 등장하는지 카운트함\n",
    "\n",
    "그 후에 생성된 텍스트 길이로 나눔\n",
    "\n",
    "하지만 이런 단순한 정밀도에는 문제가 있음\n",
    "\n",
    "생성된 텍스트에 동일 단어가 반복되고 이 단어가 참조 텍스트에 등장한다고 해보자.\n",
    "\n",
    "참조 텍스트 길이만큼 반복된다면 정밀도는 완벽함\n",
    "\n",
    "이런 이유로 BLEU 논문 저자들은 약간의 변화를 주었음\n",
    "\n",
    "단어를 참조 텍스트에 등장한 횟수만큼만 카운트함\n",
    "\n",
    "이를 설명하기 위해 참조 텍스트가 'the cat is on the mat' 이고 생성된 텍스트가 'the the the the the the' 라고 가정해보자.\n",
    "\n",
    "이 예시에서 정밀도는 이렇게 계산됨\n",
    "```\n",
    "$$P_{vanilla} = \\frac{6}{6}$$\n",
    "\n",
    "$$P_{mod} = \\frac{2}{6}$$\n",
    "\n",
    "```\n",
    "간단한 수정으로 훨씬 합리적인 값을 얻었음\n",
    "\n",
    "이제 이를 확장해 단어 하나만이 아니라 n-그램도 확인할 수 있음\n",
    "\n",
    "생성된 텍스트가 snt 와 참조 문장 snt' 를 비교한다고 해보자.\n",
    "\n",
    "특정 n 에 대해 가능한 n-그램을 추출해 정밀도를 계산함\n",
    "```\n",
    "\n",
    "$$P_n = \\frac{\\sum_{n-gram \\in snt'}Count_{clip}(n-gram)}{\\sum_{n-gram \\in snt}Count(n-gram)}$$\n",
    "\n",
    "```\n",
    "반복적인 생성에 보상을 주지 않도록 분자의 카운트는 클리핑함\n",
    "\n",
    "생성된 문장에서 n-그램의 등장 횟수를 카운트하는 것이 참조 문장에 나타난 횟수로 제한된다는 의미임\n",
    "\n",
    "이 식에서 문장의 정의는 그다지 엄격하지 않음\n",
    "\n",
    "여러 문장에 걸쳐 생성된 텍스트가 있다면 이를 하나의 문장으로 다룸\n",
    "\n",
    "일반적으로 테스트 세트는 평가할 샘플이 하나 이상 있으니 말뭉치 C 에 있는 모든 샘플을 더하도록 이 식을 조금 확장할 필요가 있음\n",
    "```\n",
    "\n",
    "$$P_n = \\frac{\\sum_{snt' \\in C}\\sum_{n-gram \\in snt'}Count_{clip}(n-gram)}{\\sum_{snt \\in C}\\sum_{n-gram \\in snt}Count(n-gram)}$$\n",
    "\n",
    "```\n",
    "재현율을 고려하지 않기 때문에 짧지만 정밀하게 생성된 시퀀스가 긴 문장보다 유리함\n",
    "\n",
    "따라서 짧게 생성된 텍스트의 정밀도 점수가 더 좋음\n",
    "\n",
    "이를 보상하기 위해 BLEU 논문의 저자들은 브레비티 페널티(Brevity Penalty)라는 추가 항을 도입했음\n",
    "```\n",
    "\n",
    "$$BR = min(1, e^{1 - \\mathcal{l}_{ref} / \\mathcal{l}_{gen}})$$\n",
    "\n",
    "```\n",
    "최솟값을 선택하므로 이 페널티는 절대 1 을 넘지 않고, 생성된 텍스트의 길이 $l_{gen}$가 참조 텍스트 $l_{ref}$ 보다 더 작을 때 지수 항이 기하급수적으로 작아짐\n",
    "\n",
    "이 시점에서 왜 재현율도 고려하는 F1-점수 같은 기준을 사용하지 않는지 궁금할거다.\n",
    "\n",
    "그 이유는 번역 데이터셋에는 하나가 아니라 여러 개의 참조 문장이 있는 경우가 있기 때문임\n",
    "\n",
    "재현율을 측정하면 전체 참조 문장에 있는 단어를 모두 사용하는 번역에 인센티브가 주어짐\n",
    "\n",
    "따라서 번역의 정밀도가 높고 번역과 참조 문장의 길이가 비슷한지 확인하는 것이 좋음\n",
    "\n",
    "마지막으로 모든 것을 합쳐서 BLEU 점수를 계산하는 공식을 만들겠음\n",
    "```\n",
    "\n",
    "$$BLEU-N = BR \\times (\\prod_{n=1}^N p_n)^{1 / N}$$\n",
    "\n",
    "```\n",
    "마지막 항은 1에서 N까지 n-그램에서 수정 정밀도의 기하 평균임\n",
    "\n",
    "BLEU-4 점수가 실제로 많이 사용됨\n",
    "\n",
    "하지만 이 지표에는 많은 제약이 있음\n",
    "\n",
    "한 예로, 동의어를 고려하지 않음\n",
    "\n",
    "유도된 식의 많은 단계가 임시방편이고 깨지기 쉬움\n",
    "\n",
    "BLEU 의 단점을 잘 설명한 레이첼 타트만(Rachael Tatman)의 블로그 포스트 'Evaluating Text Output in NLP: BLEU at Your Own Risk'(https://oreil.ly/nMXRh)를 참고하자\n",
    "\n",
    "BLEU 지표의 또 다른 약점은 토큰화된 텍스트를 기대한다는 점임\n",
    "\n",
    "만약 텍스트 토큰화를 정확히 같은 방법으로 하지 않으면 결과가 달라짐\n",
    "\n",
    "SacreBLEU 는 토큰화 단계를 내재화해 이 문제를 해결함\n",
    "\n",
    "이 때문에 벤치마킹에서는 이 지표를 선호함\n",
    "\n",
    "이 로직을 모두 파이썬으로 구현해야 할까?\n",
    "\n",
    "데이터셋은 측정 지표도 제공함\n",
    "\n",
    "지표를 로딩하는 방법은 데이터셋을 로딩하는 방법과 비슷함\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49c4086b-b926-48e4-8ef5-277c417810fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e8baf59-0f2e-4d50-9db0-ab39c3c665d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566129cf877d4991a064af094d61946d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bleu_metric = load_metric('sacrebleu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332cbdc-388e-4cad-9faa-442b9cfd44b0",
   "metadata": {},
   "source": [
    "```\n",
    "bleu_metric 객체는 Metric 클래스의 인스턴스로 하나의 수집기(Aggregator)처럼 작동함\n",
    "\n",
    "add() 메서드에 샘플 하나를 추가하거나 add_batch() 메서드로 배치 전체를 추가함\n",
    "\n",
    "평가하려는 샘플을 모두 추가한 다음 compute() 메서드를 호출하면 지표가 계산됨\n",
    "\n",
    "이 메서드는 몇 개의 값으로 구성된 딕셔너리를 반환함\n",
    "\n",
    "각 n-그램에 대한 정밀도, 길이 페널티, 최종 BLEU 점수 등임\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "456968cf-2781-4b9d-97c7-80b47ecd9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f15119a-5d83-462c-903b-a091e2a8f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0, 'counts': [2, 0, 0, 0], 'totals': [6, 5, 4, 3], 'precisions': [33.333333333333336, 0.0, 0.0, 0.0], 'bp': 1.0, 'sys_len': 6, 'ref_len': 6}\n"
     ]
    }
   ],
   "source": [
    "bleu_metric.add(\n",
    "    prediction='the the the the the the', reference=['the cat is on the mat'])\n",
    "results = bleu_metric.compute(smooth_method='floor', smooth_value=0)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93ee5e7e-163c-4497-b25c-f1d3b7fd284e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "score                          0.0\n",
       "counts                [2, 0, 0, 0]\n",
       "totals                [6, 5, 4, 3]\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]\n",
       "bp                             1.0\n",
       "sys_len                          6\n",
       "ref_len                          6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['precisions'] = [np.round(p, 2) for p in results['precisions']]\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23630eb-61cd-459e-adaa-75a9337f21a9",
   "metadata": {},
   "source": [
    "> BLEU 점수는 여러 참조 번역이 있는 경우에도 계산됨<br>이 때문에 reference 매개변수에 리스트를 전달함<br>BLEU 는 정밀도 계산을 조금 바꿔 n-그램이 하나도 없을 때 최종 점수가 0이 되는 경우를 방지함<br>이를 위한 방법으로 분자에 상수 값을 추가함<br>이렇게 하면 n-그램이 없어도 점수가 0이 되지 않음<br>이 값을 설명하기 위해 smooth_value=0 로 지정해 해당 기능을 껐음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5bfcbc-0cf1-456f-bd80-df570a4fdab6",
   "metadata": {},
   "source": [
    "```\n",
    "1-그램의 정밀도는 실제로 2/6 입니다.\n",
    "\n",
    "반면 2/3/4-그램의 정밀도는 모두 0입니다.\n",
    "\n",
    "counts 와 bp 같은 개별 지표의 자세한 내용은 SacreBLEU 저장소(https://oreil.ly/kiZPl)를 참고하세요.\n",
    "\n",
    "그러면 기하 평균이 0이 되므로 BLEU 점수도 0이 됨\n",
    "\n",
    "정밀도가 매우 높은 또 다른 예시를 확인해보자.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cf57da0-66b5-4011-b8f5-03ab830be41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(\n",
    "    prediction='the cat is on mat', reference=['the cat is on the mat'])\n",
    "results = bleu_metric.compute(smooth_method='floor', smooth_value=0)\n",
    "results['precisions'] = [np.round(p, 2) for p in results['precisions']]\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09dcb3-be8f-47b0-bf47-e4bcba4ebf5b",
   "metadata": {},
   "source": [
    "```\n",
    "정밀도 점수가 훨씬 좋아졌음\n",
    "\n",
    "예측에 있는 1-그램은 모두 맞지만 다른 정밀도 점수를 보면 틀린 예측도 있음을 알게 됨\n",
    "\n",
    "4-그램은 ['the', 'cat', 'is', 'on'] 과 ['cat', 'is', 'on', 'mat'] 두 개임\n",
    "\n",
    "두 번째를 맞추지 못했으므로 4-그램 정밀도는 0.5가 됨\n",
    "\n",
    "BLEU 점수는 텍스트 평가에 널리 사용됨\n",
    "\n",
    "가능하고 적합한 단어를 모두 포함하는 번역보다 정확한 번역이 선호되기 때문에 특히 기계 번역에 많이 쓰임\n",
    "\n",
    "이와 상황이 다른 요약 같은 애플리케이션이 있음\n",
    "\n",
    "이때는 중요한 정보가 생성된 텍스트에 모두 포함돼야 하므로 높은 재현율이 선호됨\n",
    "\n",
    "이런 작업에는 주로 ROUGE 가 사용됨\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7917d6c-1bc2-494f-8403-9eae37ca05a9",
   "metadata": {},
   "source": [
    "### 6.2.4 ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d3f4b-09b6-4061-903f-d205f1f59f45",
   "metadata": {},
   "source": [
    "```\n",
    "ROUGE 점수는 높은 재현율이 정밀도보다 훨씬 더 중요한 요약 같은 애플리케이션을 위해 특별히 개발됐음\n",
    "\n",
    "이 점수는 생성된 텍스트와 참조 텍스트에서 여러 가지 n-그램이 얼마나 자주 등장하는지 비교한다는 점에서 BLEU 와 매우 비슷함\n",
    "\n",
    "하지만 ROUGE 는 참조 텍스트에 있는 n-그램이 생성된 텍스트에 얼마나 많이 등장하는지도 확인한다는 점이 다름\n",
    "\n",
    "BLEU 는 생성된 텍스트에 있는 n-그램이 참조 텍스트에 얼마나 많이 등장하는지 봄\n",
    "\n",
    "따라서 ROUGE 는 분모에서 참조 텍스트의 n-그램이 생성된 텍스트에 얼마나 많이 등장하는지 (클리핑하지 않고) 카운트하도록 정밀도 공식을 조금 수정해 사용함\n",
    "```\n",
    "\n",
    "$$ROUGE-N = \\frac{\\sum_{snt` \\in C}\\sum_{n-gram \\in snt`}Count_{match}(n-gram)}{\\sum_{snt` \\in C}\\sum_{n-gram \\in snt`}Count(n-gram)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf859e8-0126-49ca-bd66-68357084aa3a",
   "metadata": {},
   "source": [
    "```\n",
    "이것이 ROUGE 의 원래 공식임\n",
    "\n",
    "나중에 연구자들은 정밀도를 완전히 제거하면 부정적인 영향이 커짐을 알았음\n",
    "\n",
    "클리핑 카운트를 하지 않는 BLEU 공식으로 돌아가 정밀도를 측정한 다음 정밀도와 재현율 ROUGE 점수를 조화 평균하면 F1-점수가 나옴\n",
    "\n",
    "이 점수가 오늘날 일반적으로 사용되는 ROUGE 점수임\n",
    "\n",
    "ROUGE 에는 가장 긴 공통 부분 시퀀스(Longest Common Subsequence(LCS))를 측정하는 별도의 점수 ROUGE-L 이 있음\n",
    "\n",
    "LCS 는 어떤 문자열 쌍에도 계산이 가능함\n",
    "\n",
    "예를 들어, 'abab' 와 'abc' 의 LCS 는 'ab' 이고 길이는 2임\n",
    "\n",
    "두 샘플 사이에서 이 값을 비교하려면 긴 텍스트가 유리하므로 어떤 식으로든 정규화가 필요함\n",
    "\n",
    "이를 위해 ROUGE 개발자는 F-점수와 같은 방식을 고안했음\n",
    "\n",
    "이 방식에서는 참조 텍스트와 생성 텍스트의 길이로 LCS 를 정규화한 다음 정규화된 두 점수를 혼합함\n",
    "```\n",
    "\n",
    "$$R_{LCS} = \\frac{LCS(X, Y)}{m}$$\n",
    "\n",
    "$$P_{LCS} = \\frac{LCS(X, Y)}{n}$$\n",
    "\n",
    "$$F_{LCS} = \\frac{(1 + \\beta^2)R_{LCS}P_{LCS}}{R_{LCS} + \\beta^2 P_{LCS}} (\\text{이 때}, \\beta = P_{LCS} / R_{LCS})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a37ca-7f85-49a9-8fa3-e8d5f95d15c7",
   "metadata": {},
   "source": [
    "```\n",
    "LCS 점수는 이런 식으로 적절히 정규화되어 샘플끼리 비교가 가능해짐\n",
    "\n",
    "데이터셋 구현은 두 종류의 ROUGE 점수를 계산함\n",
    "\n",
    "하나는 문장마다 점수를 계산해서 요약에 대해 평균한 점수(ROUGE-L)이고, 다른 하나는 전체 요약에 대해 계산한 점수(ROUGE-L_sum) 임\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "441d4274-f7a5-4705-85da-d79ac30ba499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87804ccbb6447eda0e6401364cfa9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge_metric = load_metric('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac0d61-4d54-407e-b1b3-4010eb3c74c7",
   "metadata": {},
   "source": [
    "```\n",
    "GPT-2 와 그 외 모델의 요약을 이미 생성했으니 이 지표로 요약을 비교하겠음\n",
    "\n",
    "모델이 생성한 모든 요약에 ROUGE 점수를 적용함\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9753e9ed-b427-4a11-8d22-b165b4cdb205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.232143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.506329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.303571  0.090909  0.214286   0.232143\n",
       "gpt2      0.187500  0.000000  0.125000   0.187500\n",
       "t5        0.486486  0.222222  0.378378   0.486486\n",
       "bart      0.582278  0.207792  0.455696   0.506329\n",
       "pegasus   0.866667  0.655172  0.800000   0.833333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset['train'][1]['highlights']\n",
    "records = []\n",
    "rouge_names = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    records.append(rouge_dict)\n",
    "    \n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659bcd6-47ad-4ec6-9273-52c5fe5700ac",
   "metadata": {},
   "source": [
    "> 데이터셋에 있는 ROUGE 지표는 신뢰 구간(Confidence Interval)(기본적으로 백분위수 5와 95 사이)도 계산함<br>mid 속성에 중앙값이 저장되고 low 와 high 속성으로 구간의 양 끝 값을 추출함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6aa2e5-db73-4c43-bcbd-baa44b732fe6",
   "metadata": {},
   "source": [
    "```\n",
    "단일 샘플만 보았으므로 이 결과를 크게 신뢰하기는 어렵지만, 한 샘플에 대한 요약 품질을 비교할 수 있음\n",
    "\n",
    "이 표에서 GPT-2 성능이 가장 낮음\n",
    "\n",
    "이 모델만 요약을 위해 명시적으로 훈련되지 않았으니 그럴 만함\n",
    "\n",
    "하지만 놀랍게도 처음 세 문장을 요약으로 사용한 간단한 기준 모델이 파라미터가 약 10억 개인 트랜스포머 모델에 비해 그다지 뒤떨어지지 않음\n",
    "\n",
    "PEGASUS 가 전반적으로 가장 좋음(ROUGE 점수가 높을수록 좋음)\n",
    "\n",
    "하지만 단일 샘플로 모델을 평가했으므로, 주의해서 결과를 다뤄야 함\n",
    "\n",
    "PEGASUS 논문의 결과를 보면 CNN/DailyMail 데이터셋에서 T5 모델보다 뛰어나며 적어도 BART 에 견줄 만하다고 기대할 수 있음\n",
    "\n",
    "PEGASUS 논문의 결과가 재현되는지 알아보자.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a7ece-6f49-4d42-aa9b-7e33cf19555e",
   "metadata": {},
   "source": [
    "## 6.5 CNN/DailyMail 데이터셋에서 PEGASUS 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2110854-169b-4dc4-ab73-e3f33bf29f6c",
   "metadata": {},
   "source": [
    "```\n",
    "CNN/DailyMail 의 테스트 세트, ROUGE 지표, 요약 모델이 준비됐으니, 모델을 평가할 요소를 모두 갖췄음\n",
    "\n",
    "처음 세 문장을 사용하는 기준 모델의 성능부터 평가해보자.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9122c13-0ba7-49c0-9aef-0017b4a26505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1187d8-3d7a-4006-a27b-2d3f81969828",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "90024d9b739b47ddace50097fc5314fd",
      "d061202731284d64941fc1478f77a92e",
      "7d324ea9fb6e43e99331511a9581cff2",
      "de0aef85f3054baebbe20057e87d0268",
      "2a81e3c0a4f642f5aaffab5ebf88dd68",
      "ca5c6d5766774199a2f3eb2d531a77f0",
      "6c50e6f7abe843269f75656478a90b40",
      "221759e7d31d4db68263819e05865d3c",
      "9e342579192b4dc195963f6061479ef0",
      "1c74996eac2e4795ab9009d69d1e8926",
      "de6bb498edd54110b40e99eb404e8b86"
     ]
    },
    "id": "ayYWw-z4jcUs",
    "outputId": "bb2792a4-4bbe-4b7a-b159-a8558f91c3dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 10:40:37.991558: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 10:40:38.508947: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2023-02-02 10:40:38.509012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2023-02-02 10:40:38.509018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Using custom data configuration default\n",
      "Reusing dataset cnn_dailymail (/home/heerak/.cache/huggingface/datasets/ccdv___cnn_dailymail/default/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db124991527543f9afd1b49f0ce308c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이 셀은 노트북 중간부터 실행하기 위한 것입니다.\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# \"cnn_dailymail\" 데이터셋 다운로드 에러가 발생할 경우 대신 \"ccdv/cnn_dailymail\"을 사용하세요.\n",
    "dataset = load_dataset(\"ccdv/cnn_dailymail\", version=\"3.0.0\") \n",
    "rouge_metric = load_metric(\"rouge\", cache_dir=None)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9883dd6-688b-4d4d-aef4-2178cdec4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return '\\n'.join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68de38d3-b901-49bb-bcb9-d5d5f6a1f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                                column_text='article',\n",
    "                                column_summary='highlights'):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries,\n",
    "                     references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3535790-0dfa-4a1e-8e7e-5b96ad729960",
   "metadata": {},
   "source": [
    "```\n",
    "CNN/DailyMail 데이터셋의 테스트 세트는 대략 10,000개의 샘플로 구성되있음\n",
    "\n",
    "이 기사 전체에서 요약을 생성하려면 많은 시간이 걸림\n",
    "\n",
    "생성되는 모든 토큰이 모델의 정방향 패스를 거쳐야 한다는 사실은 5장에서 보았음\n",
    "\n",
    "따라서 샘플마다 100개 토큰을 생성하기 위해 필요한 정방향 패스의 횟수는 백만 번임\n",
    "\n",
    "빔 서치를 사용할 경우 이 수치에 빔 크기를 곱해야 함\n",
    "\n",
    "계산을 비교적 빠르게 마치기 위해 테스트 세트에서 1,000개를 샘플링해 평가하겠음\n",
    "\n",
    "이렇게 하면 PEGASUS 모델로 단일 GPU 에서 한 시간 이내에 계산하면서 점수를 훨씬 더 안정적으로 추정할 수 있음\n",
    "\n",
    "먼저 기준 모델을 평가하자.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91177adb-82b3-4e6f-8592-fb3f935bc137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/heerak/.cache/huggingface/datasets/ccdv___cnn_dailymail/default/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f/cache-a72cfb8e548ef4fa.arrow\n",
      "Parameter 'indices'=range(0, 1000) of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "test_sampled = dataset['test'].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567b5a4d-4e31-476b-bbc3-3dcb6a08527e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.387835</td>\n",
       "      <td>0.170826</td>\n",
       "      <td>0.247057</td>\n",
       "      <td>0.35445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.387835  0.170826  0.247057    0.35445"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame.from_dict(rouge_dict, orient='index', columns=['baseline']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f3b3e-c55c-459f-930d-7711ea6b37c7",
   "metadata": {},
   "source": [
    "```\n",
    "이 점수는 이전 결과에 못 미치지만 여전히 GPT-2 보다는 좋음!\n",
    "\n",
    "이제 PEGASUS 모델을 평가할 함수를 구현해보자.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a819f3c8-9f97-4b79-8ced-62402212c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27c89103-91c0-49bf-b2ef-3e8ace768f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad88039b-120c-455c-9670-d1696fa312b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"list_of_elements 로부터 batch_size 크기의 청크를 연속적으로 생성합니다.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799aa9bb-a819-4069-9bc9-84171d3a1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text='article',\n",
    "                               column_summary='highlights'):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "    \n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        \n",
    "        inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n",
    "                           padding='max_length', return_tensors='pt')\n",
    "        \n",
    "        summaries = model.generate(input_ids=inputs['input_ids'].to(device),\n",
    "                                   attention_mask=inputs['attention_mask'].to(device),\n",
    "                                   length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        \n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                              clean_up_tokenization_space=True)\n",
    "                             for s in summaries]\n",
    "        decoded_summaries = [d.replace('<n>', ' ') for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "        \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a3873-f3fc-4eaf-a86e-cfa271ffcbe5",
   "metadata": {},
   "source": [
    "```\n",
    "이 평가 코드를 조금 자세히 알아보자.\n",
    "\n",
    "먼저 데이터셋을 동시에 처리하기 위해 작은 배치로 나눔\n",
    "\n",
    "그 다음 각 배치의 입력 샘플을 토큰화하고 generate() 함수에 전달해 빔 서치로 요약을 생성함\n",
    "\n",
    "여기서는 논문에 언급된 것과 동일한 생성 매개변수를 사용\n",
    "\n",
    "길이 페널티 매개변수는 모델이 매우 긴 시퀀스를 생성하지 않도록 함\n",
    "\n",
    "마지막으로 생성된 텍스트를 디코딩하고, <n> 토큰을 공백으로 바꾸고, 디코딩 된 참조 텍스트를 지표에 추가함\n",
    "\n",
    "마침내 ROUGE 점수를 계산하고 반환\n",
    "\n",
    "seq2seq 생성 작업에 사용하는 AutoModelForSeq2SeqLM 클래스로 이 모델을 다시 로드해 평가하자.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2669bb0a-0d49-4399-8a85-32d1adf2ab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 11:43:52.460130: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 11:43:52.979930: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2023-02-02 11:43:52.979980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2023-02-02 11:43:52.979985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec74dcec-af7a-4e29-b93e-5884b10e595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'google/pegasus-cnn_dailymail'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3beb846b-dbe2-477c-97d8-07f75f861ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [13:25<00:00,  3.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.42665</td>\n",
       "      <td>0.20749</td>\n",
       "      <td>0.305236</td>\n",
       "      <td>0.369301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rouge1   rouge2    rougeL  rougeLsum\n",
       "pegasus  0.42665  0.20749  0.305236   0.369301"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
    "                                   model, tokenizer, batch_size=4)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=['pegasus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83334534-5835-4f5e-ac8a-9f795eca1615",
   "metadata": {},
   "source": [
    "```\n",
    "이 수치는 논문 결과에 매우 근접함\n",
    "\n",
    "여기서 짚고 넘어갈 사항은 손실과 각 토큰의 정확도가 ROUGE 점수와 일정 수준 관련성이 없다는 것임\n",
    "\n",
    "손실은 디코딩 전략과 관련이 없지만, ROUGE 점수는 디코딩 전략과 밀접하게 관련됨\n",
    "\n",
    "ROUGE 와 BLEU 가 손실이나 정확도보다 사람의 판단과 더 밀접하므로 여기에 초점을 맞추고 텍스트 생성 모델을 만들 때 디코딩 전략을 주의 깊게 탐색하고 선택해야 함\n",
    "\n",
    "하지만 이런 지표가 완벽하지 않으므로 항상 사람의 판단도 고려할 필요가 있음\n",
    "\n",
    "평가 함수를 마련했으니, 이제 요약을 위한 모델을 직접 훈련해보자.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82d88e-5395-4ac2-84e7-f02e108efafb",
   "metadata": {},
   "source": [
    "## 6.6 요약 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab2ee8-d6f8-48e7-a509-d4b31f2c69b3",
   "metadata": {},
   "source": [
    "```\n",
    "삼성(Samsung)이 만든 SAMSum 데이터셋(https://oreil.ly/n1ggq)을 사용하겠음\n",
    "\n",
    "이 데이터셋은 대화와 이에 대한 짧은 요약으로 구성됨\n",
    "\n",
    "기업에서 이런 대화는 고객과 지원 센터의 상호작용을 나타냄\n",
    "\n",
    "따라서 정확한 요약을 생성하면 고객 서비스를 개선하고 고객 요청에 나타난 보편적인 패턴을 감지할 수 있음\n",
    "\n",
    "샘플을 살펴보자.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2664b939-7a17-42da-b3ea-a22d31cfb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52906548-60db-4847-85cf-35409b6d84ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0149b5bfcc3e494aa2ce1f8f6d6c3f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd55604c0374938bc87eb4a2c7eafdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/770 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset samsum/samsum (download: 2.81 MiB, generated: 10.04 MiB, post-processed: Unknown size, total: 12.85 MiB) to /home/heerak/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07fa358ef2140039dfb2052361963a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset samsum downloaded and prepared to /home/heerak/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31468d82b68d45b38996115fcff1728c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할 크기: [14732, 819, 818]\n",
      "특성: ['id', 'dialogue', 'summary']\n",
      "\n",
      "대화:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "요약:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum = load_dataset('samsum')\n",
    "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
    "\n",
    "print(f'분할 크기: {split_lengths}')\n",
    "print(f'특성: {dataset_samsum[\"train\"].column_names}')\n",
    "print('\\n대화:')\n",
    "print(dataset_samsum['test'][0]['dialogue'])\n",
    "print('\\n요약:')\n",
    "print(dataset_samsum['test'][0]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1724a96c-5dc5-4b6a-a783-73c5b11ccc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13716964',\n",
       " 'dialogue': \"Benjamin: Hey guys, what are we doing with the keys today?\\r\\nHilary: I've got them. Whoever wants them can meet me at lunchtime or after\\r\\nElliot: I'm ok. We're meeting for the drinks in the evening anyway and I guess we'll be going back to the apartment together?\\r\\nHilary: Yeah, I guess so\\r\\nDaniel: I'm with Hilary atm and won't let go of her for the rest of the day, so any option you guys choose is good for me\\r\\nBenjamin: Hmm I might actually pass by at lunchtime, take the keys and go take a nap. I'm sooo tired after yesterday\\r\\nHilary: Sounds good. We'll be having lunch with some French people (the ones who work on the history of food in colonial Mexico - I already see you yawning your head off)\\r\\nBenjamin: YAAAAWN 🙊 Where and where are you meeting?\\r\\nHilary: So I'm meeting them at the entrance to the conference hall at 2 pm and then we'll head to this place called La Cantina. Italian cuisine, which is quite funny, but that's what they've chosen\\r\\nBenjamin: Interesting 😱 To be honest, Hilary, I almost feel like changing my mind. Wanting to take this nap might end up costing me to dear\\r\\nHilary: Oh come on 😂\\r\\nBenjamin: All these terrible obstacles on mu way to bed might just prove to much to take\\r\\nHilary: We'll try to avoid talking about their subject of research. Oh wait, no, I'm actually meeting them because I wanted to chat about their research lol\\r\\nElliot: 🙉\\r\\nHilary: Do join us, we're going to have fun. And then you'll take the keys and take this most deserved of naps\\r\\nElliot: Sounds like a plan 😂\\r\\nHilary: 😎\\r\\nElliot: See you at 2 then xx\",\n",
       " 'summary': \"Hilary has the keys to the apartment. Benjamin wants to get them and go take a nap. Hilary is having lunch with some French people at La Cantina. Hilary is meeting them at the entrance to the conference hall at 2 pm. Benjamin and Elliot might join them. They're meeting for the drinks in the evening.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum['test'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d4a0e-8a15-46b2-ba78-93e65cb71a8f",
   "metadata": {},
   "source": [
    "```\n",
    "이 대화는 SMS 나 왓츠앰(WhatsApp)에서 주고 받은 내용 같음\n",
    "\n",
    "이모지와 GIF 를 위한 플레이스홀더(Placeholder)가 포함되었음\n",
    "\n",
    "dialogue 필드는 전체 텍스트를 담고 있고 summary 는 대화의 요약임\n",
    "\n",
    "CNN/DailyMail 데이터셋에서 미세 튜닝한 모델이 같은 작업을 수행할 수 있을까?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a4766-7a22-4059-bb32-5ba733c880dd",
   "metadata": {},
   "source": [
    "### 6.6.1 SAMSum 에서 PEGASUS 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c2ad38-8666-4140-8b2c-46d2435841a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8979b695-1dbc-437e-9c91-753e8d72c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약:\n",
      "Amanda: Ask Larry Amanda: He called her last time we were at the park together.\n",
      "Hannah: I'd rather you texted him.\n",
      "Amanda: Just text him .\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('summarization', model='google/pegasus-cnn_dailymail')\n",
    "pipe_out = pipe(dataset_samsum['test'][0]['dialogue'])\n",
    "print('요약:')\n",
    "print(pipe_out[0]['summary_text'].replace(' .<n>', '.\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27180e7-36ac-4b02-8522-8cb85053ce1c",
   "metadata": {},
   "source": [
    "```\n",
    "모델이 대화에서 핵심 문장을 추출해 요약하려는 것 같음\n",
    "\n",
    "CNN/DailyMail 데이터셋에는 비교적 잘 맞았겠지만 SAMSum 의 요약은 더 추상적임\n",
    "\n",
    "테스트 세트에서 ROUGE 평가를 수행해 이를 확인해보자.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b5f083e-6a2d-49c8-8659-8fae0a7c79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 205/205 [09:20<00:00,  2.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.296253</td>\n",
       "      <td>0.087794</td>\n",
       "      <td>0.229647</td>\n",
       "      <td>0.229557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.296253  0.087794  0.229647   0.229557"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = evaluate_summaries_pegasus(dataset_samsum['test'], rouge_metric,\n",
    "                                   model, tokenizer, \n",
    "                                   column_text='dialogue',\n",
    "                                   column_summary='summary',\n",
    "                                   batch_size=4)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=['pegasus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4f9df-3818-492d-b644-42a3f68d21ce",
   "metadata": {},
   "source": [
    "```\n",
    "결과가 훌륭하지 않지만, CNN/DailyMail 데이터셋이 SAMSum 과 크게 다르기 때문에 어느 정도 예상했음\n",
    "\n",
    "훈련 전에 평가 파이프라인을 준비하면 두 가지 이점이 있음\n",
    "\n",
    "훈련이 성공적인지 바로 평가가 가능해졌고 기준점이 세워진 것임\n",
    "\n",
    "이 데이터셋에서 모델을 미세 튜닝하면 ROUGE 점수가 바로 향상되어야 함\n",
    "\n",
    "그렇지 않으면 훈련 과정에 문제가 있는 것임\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9fea14-79b8-48d6-9922-ae844a22a058",
   "metadata": {},
   "source": [
    "### 6.6.2 PEGASUS 미세 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a5d53d-10a0-4098-a10f-8aa4bdf06820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum['train']['dialogue']]\n",
    "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum['train']['summary']]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
    "axes[0].hist(d_len, bins=20, color='C0', edgecolor='C0')\n",
    "axes[0].set_title('Dialogue Token Length')\n",
    "axes[0].set_xlabel('Length')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[1].hist(s_len, bins=20, color='C0', edgecolor='C0')\n",
    "axes[1].set_title('Summary Token Length')\n",
    "axes[1].set_xlabel('Length')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54445a7d-5e19-49e9-be8c-7fbf40d26b79",
   "metadata": {},
   "source": [
    "```\n",
    "대부분 대화는 100~200개 토큰으로 구성되며 CNN/DailyMail 기사보다 훨씬 더 짧음\n",
    "\n",
    "마찬가지로 요약도 20~30개 토큰(평균 트윗 길이)으로 구성되며 훨씬 더 짧음\n",
    "\n",
    "이런 점을 유념하면서 Trainer 를 위한 데이터 콜레이터를 만들겠음\n",
    "\n",
    "먼저 데이터셋을 토큰화하자.\n",
    "\n",
    "대화와 요약의 최대 길이를 각각 1024와 128로 설정하겠음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa605ad-b14f-4c02-9e1b-b1e7b5cf016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch['dialogue'], max_length=1024,\n",
    "                                truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodigns = tokenizer(example_batch['summary'], max_length=128,\n",
    "                                     truncation=True)\n",
    "        \n",
    "    return {'input_ids': input_encodings['input_ids'],\n",
    "            'attention_mask': input_encodings['attention_mask'],\n",
    "            'labels': target_encodigns['input_ids']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bf8f37-f650-4977-8f8f-9c5fae26790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function convert_examples_to_features at 0x7f55bce1f670> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf063ecb366457faddc613703af16d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9145abe4f14502baa89f4efa40ea60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78f6c51620a419b84ef0d28c153fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n",
    "                                       batched=True)\n",
    "columns = ['input_ids', 'labels', 'attention_mask']\n",
    "dataset_samsum_pt.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74409e-89d7-4d5d-b8cc-c4865bffa54c",
   "metadata": {},
   "source": [
    "```\n",
    "토큰화 단계에 새롭게 적용한 것은 tokenizer.as_target_tokenizer() 임\n",
    "\n",
    "일부 모델은 디코더 입력에 특수 토큰이 필요함\n",
    "\n",
    "따라서 인코더와 디코더 입력의 토큰화를 구별하는 것이 중요함\n",
    "\n",
    "(컨텍스트 매니저(Context Manager)라 부르는) with 문을 사용하면 토크나이저가 디코더를 위한 토큰화임을 인지하고 그에 따라 시퀀스를 처리할 수 있음\n",
    "\n",
    "이제 데이터 콜레이터를 만듭니다.\n",
    "\n",
    "이 함수는 배치를 모델에 주입하기 전에 Trainer 에 의해 호출됨\n",
    "\n",
    "대부분의 경우 단순히 배치에 있는 모든 텐서를 가져오 쌓는 기본 콜레이터를 사용함\n",
    "\n",
    "요약 작업에서는 입력을 쌓을 뿐만 아니라 디코더 쪽의 타깃도 준비함\n",
    "\n",
    "PEGASUS 는 인코더-디코더 트랜스포머이고, 따라서 고전적인 seq2seq 구조를 취함\n",
    "\n",
    "seq2seq 구조에서는 디코더에 '티처 포싱(Teacher Forcing)'을 적용하는 것이 일반적임\n",
    "\n",
    "이 전략에서는 (GPT-2 등의 디코더 전용 모델처럼) 디코더가 인코더 출력 외에 한 토큰이 이동된 레이블로 구성된 입력 토큰을 받음\n",
    "\n",
    "따라서 아래 표처럼 다음 토큰을 위한 예측을 만들 때 디코더는 한 토큰이 이동된 정답을 입력으로 받음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9df9a1-d33a-45f4-8cba-e84f9436ff3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>Transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[PAD, Transformers]</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[PAD, Transformers, are]</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PAD, Transformers, are, awesome]</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[PAD, Transformers, are, awesome, for]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[PAD, Transformers, are, awesome, for, text]</td>\n",
       "      <td>summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     decoder_input          label\n",
       "step                                                             \n",
       "1                                            [PAD]   Transformers\n",
       "2                              [PAD, Transformers]            are\n",
       "3                         [PAD, Transformers, are]        awesome\n",
       "4                [PAD, Transformers, are, awesome]            for\n",
       "5           [PAD, Transformers, are, awesome, for]           text\n",
       "6     [PAD, Transformers, are, awesome, for, text]  summarization"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 티처 포싱(Teacher Forcing)\n",
    "# 텍스트 생성을 위한 디코더 입력과 레이블의 정렬\n",
    "text = ['PAD', 'Transformers', 'are', 'awesome', 'for', 'text', 'summarization']\n",
    "rows = []\n",
    "for i in range(len(text) - 1):\n",
    "    rows.append({'step': i+1, 'decoder_input': text[:i+1], 'label': text[i+1]})\n",
    "pd.DataFrame(rows).set_index('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19266132-4cfd-458b-ac20-7def2c0e0b11",
   "metadata": {},
   "source": [
    "```\n",
    "한 스텝 이동했으므로 디코더는 이전 스템의 정답 레이블만 보며 현재와 미래의 레이블을 보지 못함\n",
    "\n",
    "디코더는 현재와 미래의 모든 입력을 마스킹하는 마스크드 셀프 어텐션을 갖기 때문에 이동시키는 것으로 충분함\n",
    "\n",
    "따라서 배치를 준비할 때 레이블을 한 스텝 오른쪽으로 이동시켜 디코더 입력을 만듦\n",
    "\n",
    "그런 다음 레이블에 있는 패딩 토큰을 -100 으로 설정해 손실 함수가 무시하도록 만듦\n",
    "\n",
    "그러나 DataColloatorForSeq2Seq 에서 이런 작업을 모두 처리하므로 실제로 이를 수동으로 할 필요가 없음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a92eee-3e04-4f48-903f-0b0779ea1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92020c5f-a80a-4566-84eb-16c6fca39aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214deea8-f0aa-440c-bc63-1e42c7f38de3",
   "metadata": {},
   "source": [
    "```\n",
    "이제 이전처럼 훈련을 위해 TrainingArguments 를 설정하자\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "086a8a37-bd82-42c0-a8f3-fa295f6d5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2c43c12-69f4-46c0-ab37-52248c0d9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='pegasus-samsum', \n",
    "    num_train_epochs=1,\n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    push_to_hub=True,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=500,\n",
    "    save_steps=1e6,\n",
    "    gradient_accumulation_steps=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a47136-59a9-44c1-9ea5-0a61f3737e43",
   "metadata": {},
   "source": [
    "```\n",
    "이전과 달리 새 매개변수 gradient_accumulation_steps 가 추가되었음\n",
    "\n",
    "모델이 매우 크니 배치 크기를 1로 지정하는데, 배치 크기가 너무 작으면 수렴하지 않음\n",
    "\n",
    "이 문제를 해결하기 위해 그레디언트 누적(Gradient Accumulation)이라는 멋진 기술을 사용함\n",
    "\n",
    "이름 그대로 큰 배치의 그레이덩ㄴ트를 한 번에 계산하는 대신 작은 배치를 만들고 그레디언트를 누적하는 방식임\n",
    "\n",
    "그레디언트가 충분히 누적되면 최적화 단계를 수행함\n",
    "\n",
    "당연히 이는 한 번에 실행하는 것보다 조금 더 느림\n",
    "\n",
    "하지만 GPU 메모리가 많이 절약됨\n",
    "\n",
    "훈련이 끝난 후 모델을 허브에 저장하기 위해 허깅페이스에 로그인함\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab3aadb-725a-4454-8499-8a8d9cded445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d5f1c-4162-4a58-82ff-e1cf87ca5942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e579f9-9ffe-4a68-a68f-a4259f9f80ac",
   "metadata": {},
   "source": [
    "```\n",
    "이제 Trainer 를 초기화하기 위해 필요한 모델, 토크나이저, 훈련 매개변수, 데이터 콜레이터, 훈련 세트, 평가 세트가 모두 준비됐음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "313164a1-8117-452b-a3f1-75bead0632b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/heerak/workspace/nlp-with-transformers/pegasus-samsum is already a clone of https://huggingface.co/Heerak/pegasus-samsum. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  args=training_args,\n",
    "                  tokenizer=tokenizer,\n",
    "                  data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt['train'],\n",
    "                  eval_dataset=dataset_samsum_pt['validation'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c22231-00f6-4ee9-917b-0939b9bbcfa3",
   "metadata": {},
   "source": [
    "```\n",
    "훈련할 준비가 끝났음\n",
    "\n",
    "훈련을 마친 후 테스트 세트로 평가 함수를 실행해 모델의 성능을 확인함\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a12fa944-a505-4698-b804-94a8c4904ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: id, summary, dialogue.\n",
      "***** Running training *****\n",
      "  Num examples = 14732\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 920\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraki-1203\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/heerak/workspace/nlp-with-transformers/wandb/run-20230202_104137-1bcae9rs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/raki-1203/huggingface/runs/1bcae9rs\" target=\"_blank\">pegasus-samsum</a></strong> to <a href=\"https://wandb.ai/raki-1203/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/920 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 10.76 GiB total capacity; 8.95 GiB already allocated; 189.25 MiB free; 9.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m score \u001b[38;5;241m=\u001b[39m evaluate_summaries_pegasus(dataset_samsum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m                                    rouge_metric,\n\u001b[1;32m      4\u001b[0m                                    trainer\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m                                    column_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                                    column_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m rouge_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((rn, score[rn]\u001b[38;5;241m.\u001b[39mmid\u001b[38;5;241m.\u001b[39mfmeasure) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m rouge_names)\n",
      "File \u001b[0;32m/data/heerak/workspace/venv3.8/lib/python3.8/site-packages/transformers/trainer.py:1316\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1316\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1319\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1322\u001b[0m ):\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/data/heerak/workspace/venv3.8/lib/python3.8/site-packages/transformers/trainer.py:1867\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1867\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/data/heerak/workspace/venv3.8/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/heerak/workspace/venv3.8/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 10.76 GiB total capacity; 8.95 GiB already allocated; 189.25 MiB free; 9.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "score = evaluate_summaries_pegasus(dataset_samsum['test'],\n",
    "                                   rouge_metric,\n",
    "                                   trainer.model,\n",
    "                                   tokenizer,\n",
    "                                   batch_size=2,\n",
    "                                   column_text='dialogue',\n",
    "                                   column_summary='summary')\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=['pegasus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378e419-4849-4527-844a-3eaade02d54a",
   "metadata": {},
   "source": [
    "```\n",
    "미세 튜닝하지 않은 모델에 비해 ROUGE 점수가 상당히 향상됐음\n",
    "\n",
    "이전 모델도 요약에 대해 훈련됐지만 새로운 데이터셋에 잘 적응하지 못했음\n",
    "\n",
    "이 모델을 허브에 저장하자\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8425c12b-6c4e-4677-a64d-3973e50af541",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub('Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac0af66-2561-4789-a7c0-a907f748bf25",
   "metadata": {},
   "source": [
    ">TIP<br>훈련 루프의 일부로 생성된 텍스트를 평가할 수 있음<br>Seq2SeqTrainingArguments 란 이름의 TrainingArguments 의 확장을 사용하고 predict_with_generate=True 를 지정합니다.<br>이를 Seq2SeqTrainer 란 이름의 전용 Trainer 에 전달합니다.<br>그러면 평가를 위해 모델의 정방향 패스가 아니라 generate() 함수를 사용해 예측을 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f0b44-97fb-42ee-8b1f-72780aa72774",
   "metadata": {},
   "source": [
    "### 6.6.3 대화 요약 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f53a55-49ab-4036-9177-72869e8e7abc",
   "metadata": {},
   "source": [
    "```\n",
    "손실과 ROUGE 점수를 보면 CNN/DailyMail 에서만 훈련한 원래 모델보다 크게 향상된 것 같음\n",
    "\n",
    "테스트 세트에 있는 샘플로 어떤 요약이 만들어지는지 확인해보자.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0893f8ea-1213-4eee-a29a-de87957fdc49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_samsum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gen_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_penalty\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_beams\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m8\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m128\u001b[39m}\n\u001b[0;32m----> 2\u001b[0m sample_text \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_samsum\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m reference \u001b[38;5;241m=\u001b[39m dataset_samsum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# `transformersbook` 을 자신의 허브 사용자 이름으로 바꾸세요.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_samsum' is not defined"
     ]
    }
   ],
   "source": [
    "gen_kwargs = {'length_penalty': 0.8, 'num_beams': 8, 'max_length': 128}\n",
    "sample_text = dataset_samsum['test'][0]['dialogue']\n",
    "reference = dataset_samsum['test'][0]['summary']\n",
    "# `transformersbook` 을 자신의 허브 사용자 이름으로 바꾸세요.\n",
    "pipe = pipeline('summarization', model='transformersbook/pegasus-samsum')\n",
    "\n",
    "print('대화:')\n",
    "print(sample_text)\n",
    "print('\\n참조 요약:')\n",
    "print(reference)\n",
    "print('\\n모델 요약:')\n",
    "print(pipe(sample_text, **gen_kwargs)[0]['summary_texet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4dc773-3567-4834-84b8-a416b68c782c",
   "metadata": {},
   "source": [
    "```\n",
    "참조 번역과 훨씬 비슷해졌음\n",
    "\n",
    "모델이 그냥 문장을 추출하지 않고 대화를 합성해서 요약을 만드는 법을 배운 것 같음\n",
    "\n",
    "실제 대화 입력에서 이 모델이 얼마나 잘 동작할까?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0740d1-3042-4376-8f1a-2005f7bbf64f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m custom_dialogue \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mThom: Hi guys, have you heard of transformers?\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mLewis: Yes, I used them recently!\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mLewis: Awesome, let\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms do it together!\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpipe\u001b[49m(custom_dialogue, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgen_kwargs)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "custom_dialogue = \"\"\"\\\n",
    "Thom: Hi guys, have you heard of transformers?\n",
    "Lewis: Yes, I used them recently!\n",
    "Leandro: Indeed, there is a great library by Hugging Face.\n",
    "Thom: I know, I helped build it ;)\n",
    "Lewis: Cool, maybe we should write a book about it. What do you think?\n",
    "Leandro: Great idea, how hard can it be?!\n",
    "Thom: I am in!\n",
    "Lewis: Awesome, let's do it together!\n",
    "\"\"\"\n",
    "print(pipe(custom_dialogue, **gen_kwargs)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8d407-67a1-4e17-9a02-8a589c5a6ffb",
   "metadata": {},
   "source": [
    "```\n",
    "임의로 작성한 대화에서 타당성 있는 요약을 생성했음\n",
    "\n",
    "대화에서 그냥 하나의 문장을 뽑아 내지 않고 대화에 참여한 사람 모두가 책을 함께 쓰고 싶다는 내용을 잘 요약했음\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e9daa-4d39-4128-8c18-d07109d7f21b",
   "metadata": {},
   "source": [
    "## 6.7 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1968ea0-6a19-453f-be3a-b63285b593e1",
   "metadata": {},
   "source": [
    "```\n",
    "텍스트 요약은 감성 분석, 개체명 인식, 질문 답변과 같이 분류 작업으로 구성되는 작업에 비해 특수한 어려움이 몇 가지 있음\n",
    "\n",
    "정확도 같은 전통적인 지표는 생성된 텍스트의 품질을 반영하지 못함\n",
    "\n",
    "BLEU 와 ROUGE 지표가 생성된 텍스트를 더 잘 평가함\n",
    "\n",
    "하지만 여전히 사람의 판단이 가장 좋은 척도임\n",
    "\n",
    "요약 모델로 작업할 때는 주로 모델의 문맥 크기보다 긴 텍스트를 어떻게 요약할지에 의문이 생김\n",
    "\n",
    "안타깝게도 이 문제를 해결할 수 있는 단일 전략은 없음\n",
    "\n",
    "아직까지도 활발하게 연구되고 있는 미결의 문제임\n",
    "\n",
    "OpenAI 의 최근 연구는 긴 문서에 반복적으로 모델을 적용하고 사람의 피드백을 반복 루프에 추가해 요약 작업의 스케일을 확장했음\n",
    "\n",
    "다음 장에서 텍스트 기반의 질문에 답을 제공하는 질문 답변에 대해 알아보겠음\n",
    "\n",
    "요약과 달리, 이 작업에는 길이가 길거나 대량의 문서를 다룰 좋은 전략이 있음\n",
    "\n",
    "질문 답변 작업을 수천 개의 문서로 확장하는 방법을 알아보겠음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e41509-d002-42c5-bb02-968cf4322f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5853e-30c6-4536-bd1f-f6a5e5778d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67569d7c-7bda-49a3-bad4-f3d6be79bdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599c9ab-5fe6-4593-a155-5a6ff3118d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8404ca44-0f69-43fa-ba23-6da7cc6d20a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1f11a-93ac-4bad-aeaa-8421ecce8258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a8cf8-ee12-4a86-b016-2e50ea928917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ccc2e-6c51-431e-954e-ac0b3f1944dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
